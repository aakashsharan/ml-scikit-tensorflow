{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:45.765675Z",
     "start_time": "2019-05-10T14:16:42.904030Z"
    }
   },
   "outputs": [],
   "source": [
    "# import jtplot module in notebook\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "# choose which theme to inherit plotting style from\n",
    "# onedork | grade3 | oceans16 | chesterish | monokai | solarizedl | solarizedd\n",
    "jtplot.style(theme='grade3', context='paper', fscale=1.5, spines=True, ticks=False)\n",
    "\n",
    "#jtplot.style(context='talk', fscale=1.4, spines=False, gridlines='--')\n",
    "#jtplot.style(ticks=True, grid=False, figsize=(6, 4.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:45.818998Z",
     "start_time": "2019-05-10T14:16:45.768355Z"
    }
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#mpl.rc('axes', lablesize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# location to save figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep-learning\"\n",
    "\n",
    "def image_path(fig_id):\n",
    "    return os.path.join(PROJECT_ROOT_DIR, \"images\", fig_id + \".png\")\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images/\"+ CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=\"png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Vanishing/Exploding Gradients Problem**\n",
    "\n",
    "**vanishing gradient:** gradients often get smaller and connection weights virtually unchanged.    \n",
    "**exploding gradient:** gradients grow bigger and bigger and insanely get large weights. alogrithm diverges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:45.823252Z",
     "start_time": "2019-05-10T14:16:45.821283Z"
    }
   },
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:46.145999Z",
     "start_time": "2019-05-10T14:16:45.824816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "#save_fig(\"sigmoid_saturation_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Xavier and He Initialization**\n",
    "\n",
    "The dense() function is almost identical to the fully_connected() function. The main differences relevant to this chapter are:\n",
    "\n",
    "+ several parameters are renamed: scope becomes name, activation_fn becomes activation (and similarly the _fn suffix is removed from other parameters such as normalizer_fn), weights_initializer becomes kernel_initializer, etc.\n",
    "+ the default activation is now None rather than tf.nn.relu.\n",
    "+ it does not support tensorflow.contrib.framework.arg_scope()\n",
    "+ it does not support regularizer params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:49.393498Z",
     "start_time": "2019-05-10T14:16:46.147530Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:49.484950Z",
     "start_time": "2019-05-10T14:16:49.395781Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28 #MNIST\n",
    "n_hidden1 = 300\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:49.524871Z",
     "start_time": "2019-05-10T14:16:49.488215Z"
    }
   },
   "outputs": [],
   "source": [
    "he_init = tf.variance_scaling_initializer() # he init = variance_scaling_initializer()\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, kernel_initializer=he_init, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Nonsaturating Activation Functions**\n",
    "\n",
    "ReLU activation function is saturating: during training some neurons die dying ReLus, meaning they stop outputting anything other than 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Leaky ReLu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:49.530346Z",
     "start_time": "2019-05-10T14:16:49.527049Z"
    }
   },
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:49.626898Z",
     "start_time": "2019-05-10T14:16:49.532575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "#save_fig(\"leaky_relu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Leaky ReLU in TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:49.633045Z",
     "start_time": "2019-05-10T14:16:49.628529Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:49.656122Z",
     "start_time": "2019-05-10T14:16:49.634980Z"
    }
   },
   "outputs": [],
   "source": [
    "def leaky_relu(z, name=None):\n",
    "    return tf.maximum(0.01 * z, z, name=name)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a neural network on MNIST using the Leaky ReLU. First let's create the graph:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:49.660326Z",
     "start_time": "2019-05-10T14:16:49.657696Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:49.670718Z",
     "start_time": "2019-05-10T14:16:49.662926Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:49.727636Z",
     "start_time": "2019-05-10T14:16:49.672613Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=leaky_relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:49.736928Z",
     "start_time": "2019-05-10T14:16:49.729243Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:49.813659Z",
     "start_time": "2019-05-10T14:16:49.738476Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:49.820639Z",
     "start_time": "2019-05-10T14:16:49.814840Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:49.840992Z",
     "start_time": "2019-05-10T14:16:49.822160Z"
    }
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:50.592540Z",
     "start_time": "2019-05-10T14:16:49.842365Z"
    }
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:50.599171Z",
     "start_time": "2019-05-10T14:16:50.594738Z"
    }
   },
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:50.609813Z",
     "start_time": "2019-05-10T14:16:50.600637Z"
    }
   },
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:16:50.619900Z",
     "start_time": "2019-05-10T14:16:50.612085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"train/GradientDescent\"\n",
       "op: \"NoOp\"\n",
       "input: \"^train/GradientDescent/update_hidden1/kernel/ApplyGradientDescent\"\n",
       "input: \"^train/GradientDescent/update_hidden1/bias/ApplyGradientDescent\"\n",
       "input: \"^train/GradientDescent/update_hidden2/kernel/ApplyGradientDescent\"\n",
       "input: \"^train/GradientDescent/update_hidden2/bias/ApplyGradientDescent\"\n",
       "input: \"^train/GradientDescent/update_outputs/kernel/ApplyGradientDescent\"\n",
       "input: \"^train/GradientDescent/update_outputs/bias/ApplyGradientDescent\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_op.node_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:18:28.859521Z",
     "start_time": "2019-05-10T14:16:50.621632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.9 Validation accuracy: 0.9\n",
      "5 Batch accuracy: 0.94 Validation accuracy: 0.942\n",
      "10 Batch accuracy: 0.92 Validation accuracy: 0.9608\n",
      "15 Batch accuracy: 0.94 Validation accuracy: 0.9702\n",
      "20 Batch accuracy: 1.0 Validation accuracy: 0.9716\n",
      "25 Batch accuracy: 1.0 Validation accuracy: 0.9744\n",
      "30 Batch accuracy: 0.98 Validation accuracy: 0.9772\n",
      "35 Batch accuracy: 0.98 Validation accuracy: 0.9772\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "            print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **ELU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:18:28.862928Z",
     "start_time": "2019-05-10T14:18:28.860918Z"
    }
   },
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:18:29.118065Z",
     "start_time": "2019-05-10T14:18:28.864691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEMCAYAAADUEk3/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VOXZ//FPZrJvkIQt7FsIQURbl9ZtHNdRq7XWqrRqVcTHVvSpVVqFuuBSrRXx6eOD9lcFFdyXWsWK01Y7HRRbl1oFDRCQnRAg+zaZ9ffHmaxmhUnOZOb7fr3ymuScM+e+5p57rtxz5ppzEkKhECIiMvhZzA5AREQiQwldRCRGKKGLiMQIJXQRkRihhC4iEiOU0EVEYoQSuohIjFBCFxGJEYlmByCxwW5zPAUMc7md58ZIOxbgMeAHQC5wisvtdPVnm93E8hQD8JjDbeUAG4DjXW7nlv5ur6/sNscrwFqX27nE7FiikRK6CcIv0Cs6WfUvl9v57Z5ewHabwwWsd7md13dYfiXwfy63MzOiAfeibeBnQMJga6cb5wBXAXbgK6BiANrs6nEP1GMGWAi8ZUYyt9scNmA+cBQwGrjK5XY+1WGzu4B/2G2OZS63s3qAQ4x6Sujm+RtweYdlXjMCiYSBenEN4It4KlDqcjvXDlB7XRqox2y3OdKBucB5A9FeJzKB9cCK8M/XuNzOdXab4yvgMmDpAMY2KCihm6fJ5XbuHehG7TbHWcCvgJlACPgIuNHldhaH1ycANwE/AcYD+4GVLrdzQfidw8nAyXabY154l5Ncbue25ncVwCrgbmCMy+30t2n3OSDD5Xae31McvWmn+d2L3eZIAR4AfggMAf4DzHe5ne+F17uAL4Eq4L+AIEay+KXL7Qx20UdPEX4HZbc5QsB2l9s5sbPZc9t4etPWwfQvsKgvj/lgHzfGu5Ig8H4nfXIU8FvgeGA3MAcYBfzM5Xae0MX++sTldr4FvBVu76luNn0D47EroXegD0XjTwbwP8CxGIcTqoFVdpsjObz+PuB24H7gMOAiYGd43c+AD4AngfzwT/O6Zi8BQ4HTmxfYbY4M4HzgmV7G0Zt2mv0WuAQjwXwDWAe8bbc58ttscyngx0hG1wM3hu/TlZ9h/FPaFW77mG627aintg61f6F3j7k3sXR0EvCJy+1sd8Y+u81xDLAG+DswC/gnxqGPX4UfCx22X2i3Oep6+Dmpmzh68iFwrN3mSDuEfcQkzdDNc5bd5qjrsGypy+28pT8bdbmdr7b9225zXAXUYLxA/gP8HGOmvDy8yWaMJIPL7ay22xxeoKGrdxcut7PSbnO8hZFM3g4vvgAjsazqTRwut/O9ntoJ3ycD+Ckw1+V2/jm87CfAqcA84Lbwpl+63M47wr9vstsc1wCnAc938Riq7TZHLRA4iHdRXbZltzkyOYj+tdscB/OY+/y4gQlAaSfLHwJWudzOe8PtPYfxXLpdbue7nWz/e4x/7N3Z3cP67uwBkjCOs0fdB7dmUkI3jxvjrXBbVf3dqN3mmALcA3wLGI7xLs2C8fbfC6QA7xxiM88AT9ltjnSX29mAkdxfcbmdnl7G0VtTMF7YLYcIXG5nwG5zfADMaLPd5x3utwcY0Yd2+qK7tmZw6P3b28fcUyydSQPK2i6w2xyjMGbup7RZ7MV4rr42Ow/HU0H/fojcGL7VDL0DJXTzNLjczs0Hed8ajGOnHQ3FOHTRnVUYs6Nrw7d+jGOtyUSukuLN8H7Pt9sc72AcfjmzD3H0VnO8nZ3Uv+0yXyfrDuZwY5Cv91FSh7+7aysS/dvbx9xTLJ05AOR0WFYUvv2ozbJCYGPbY/Zt2W2OhRjVMt052+V2rulhm67khm/3H+T9Y5aOoQ9OG4Fvhj9ga+ub4XWdstsceRgv0Ptcbuffwh+EZtH6j/1LoAnjbXlXvIC1u+BcbmcT8ArGzPwSYC/wjz7E0at2MA5XeIET2+zbChwXfiyRth/juHZbR/Th/pHo3/58zJ/y9Vn+UIx/BM0f6mZhHDtv6GY/vweO7OHn40OIcyawx+V2lvW4ZZzRDN08KeG3s20FXG5n86wj225zHNlhfZXL7dyG8YWX64FH7DbH44AHo0LhhxgfPnalEmMWdo3d5tgJjAEexJgd43I7a+02x++A++02RxPGYaE84CiX2/lYeB/bMI63TwTqgIouqiaewSjNnAQ812GbbuPobTsut7PebnM8BvzGbnMcALZiHKMeCTzaTT8crHeB/7HbHN/F+Md5LTAuHGuPDrZ/O+yjPx+zE3jAbnPkudzO8vCy/2C8K1hgtzmexXieSoGpdpujwOV2lnTyOA/qkEv4M4ap4T8twPjwa6DC5XbuaLPpSbR+PiNtaIZuntMxXhhtfz5ts/6k8N9tfxYDuNzOrwAbUAD8BeNT/9nAReHSr06FE+IlGJUK6zHKvm7HmDU2W4BREnc7UAy8Coxts34xxgzxS4wZa1fHvN0Yh1Jm0L66pbdx9LadWzA+gHsSI/nMAs5yuZ2dfbh3qJa3+XkfI+G+1sd9RKJ/++Uxu9zOdbSOpeZlWzFm5D8FPgNqMcbueiDSNfpH0zrW0zAqaT7FqDgCwG5zpGJ8yP54hNuOCQm6pqiINAt/P+B3wAyX2xkwO56OwvX557vczo6fyQiaoYtIGy63822Md0xje9rWJD7gBrODiFaaoYuIxAjN0EVEYoQpVS7z5t+RgPGWrsaM9kVEBrFsYNfSxXd/7fCKWWWLY4EdPW4lIiKdGU8n5/kxK6HXANzzq5tIS001KQQIBAIUFxdTVFSE1drTd1him/qiVeneUs4+62xWv72a/FEdv0cUX6JxXHgDQeYv28D6HXVMH5vJkrmFpCb2f2zR0BeNHg+3/3oJdHF0w9QvFqWlppKWZm5CT05OIi0tNWoGq1nUF61SU1Lw+32kpqSYOj6jQbSNi1AoxIMvbuGzHU2MGJLBg1fPJCerL2eLOHjR1hed0YeiIjJoPOsq5c2P9pOSZGHxnEKGZQ9MMh8slNBFZFBY82Ulj/x5OwB3/Wgq08f225UWB62IHnKx2xzPYJx4KAPjhEy/dbmdT0SyDRGJP1tKG7j9mU2EQnDtWeM4dVae2SFFpUjP0O8HJrrczmzgu8C94UtXiYgclMo6Hzct30BDU5Azj8xjzuljzA4pakV0hu5yO79o82co/DMF+KSz7QOBAIGAeaeLaG7bzBiihfqiVTAYbLmN9/4we1z4/EFueWojpRVNFI3NYMFFk1qen4Fmdl/0pu2IV7nYbY5HgSsxzpb2KeGLvnamuLiY5OSO1wcYeMXFxWaHEDXUF1BRYZz5taSkhPLy8h62jg9mjItQKMSKD7z8Z2uAoWkJzPl2gM0b++M0931j5mvE6+14zZL2Ip7QXW7ndXab4waME+7baX9K1HaKiopML1s0u640WqgvWpWWGmehLSgoID9fdehmjYvn3Xt5b/MOUpIsLJk7naJx5n4IGg2vkcZGD/BGl+v7pQ49fNrN9+w2x2UY51H+3862s1qtUZE8oiWOaKC+AIvF0nIb733RbKDHxdriSv7vz8aXye+YPYWZEzu74qI5zHyN9NRuf5ctJmIcQxcR6ZWv9jbwq2dKCIZg7pljOePIYWaHNGhEbIZutzlGAKdiXCC4EeOqJj8EfhSpNkQktlXV+bh5+QbqPQFOOyKPuWdE62nZo1MkD7mEMA6v/B5j5r8duNHldr4ewTZEJEb5/EFuXbGJ3eVNTB+bwZ2zp2CxdLwOunQnYgk9fHHjkyO1PxGJH6FQiMWvbeXfW2oYlp3Eg1cVkpqszy/6Sl/9FxHTvfTeXl775z5SEhN48KpCRg5NMTukQUkJXURM9cGGKh5+fRsAt10ylcPGZ5kb0CCmhC4iptlW1sivVm4iGII5p4/B8U1VtBwKJXQRMUV1g1HRUucJcOqsXP7LMc7skAY9JXQRGXD+QJAFT29i5wEPhWMyuHP2VFW0RIASuogMuIf+tI2PN9eQm5XE4qsKSUtRRUskKKGLyIB6+b29vLq2jOTmipYcVbREihK6iAyYf22sYsnrWwG47eIpHD5BFS2RpIQuIgNi+/5GFq7cRCAIV542hrOOGm52SDFHCV1E+l1Ng5+bl22gtjHAyTNz+MlZqmjpD0roItKv/IEgC1dsYsd+DwWj07nrRwWqaOknSugi0q8efn0bH5ZUk5uZxENzppOuipZ+o4QuIv3mlbV7efn9MpKsCfz2ykJGqaKlXymhi0i/+KikmodeMypaFl48hVmTVNHS35TQRSTiduxvZMHTGwkE4fJTRvOdo1XRMhCU0EUkomobjYqWmsYAJ83I4bpzxpsdUtxQQheRiPEHQixcsYnt+z1MzU/n7ksLsKqiZcAooYtIxPxu1Tb+tamanMxEFs8pJCNVFS0DSQldRCLitQ/KeHHNXhKtCTxwRSGjc1PNDinuKKGLyCH7ZHM1v/1juKLlB5M5cnK2yRHFJyV0ETkkuw54uOXpTQSCIS49OZ9zjx1hdkhxSwldRA5aXaOfm5dvoKbBzwlFQ7n+3AlmhxTXlNBF5KAEgiFue6aErWWNTB6Vxj2XqaLFbEroInJQ/nfVdtZuqGJIeiIPzZlOZmqi2SHFPSV0Eemz1/9VxvPuUqOi5cpCxuSpoiUaKKGLSJ/8e0sND7xqVLTccuEkvjlFFS3RQgldRHptd7mHW5/eiD8Q4oe2fM7/1kizQ5I2lNBFpFfqPEZFS1W9n+OmD+UGVbREHSV0EelRIBji9mdK+GpvI5NGpvHrywpItKqiJdoooYtIjx59ayfvF1eR3VzRkqaKlmgUsWfFbnOkAI8CpwO5wGZgocvtXB2pNkRk4L2/2c9za/ditSTwwBXTGDtMFS3RKpIz9ERgJ3AyMAS4HXjJbnNMjGAbIjKAPttay8p/egH45fcncdTUISZHJN2J2Azd5XbWA4vaLHrTbnNsBY4CtnV2n0AgQCAQiFQIfdbctpkxRAv1RatgMNhyG8/9UVrRxK0rSggE4QfHj+C7xw6L6/6IhtdIT23324Ewu80xEpgGfNHVNsXFxSQnJ/VXCL1WXFxsdghRQ30BFRUVAJSUlFBeXm5yNObw+EL8ZrWHqvoQM/ItnD65lvXr15sdVlQw8zXi9fq6Xd8vCd1ucyQBzwJPu9zODV1tV1RURFqaecfjAoEAxcXFFBUVYbXG94n41RetSktLASgoKCA/P9/kaAZeMBji1hUl7K5qZPzwFK492cLMw2bE/biIhtdIY6MHeKPL9RFP6HabwwKsBLzA9d1ta7Vao2KQREsc0UB9ARaLpeU2HvvisdXbWfNlFdlpVhZfWUh12WaNizbM7Iue2o1o2aLd5kgAlgEjgQtdbmf37w9EJKr8+eP9rPj7HqwWuP+KQsYNV0XLYBLpOvTHgCLgPJfb2RjhfYtIP/p8ay33vbQFgJsvmMQxBapoGWwiWYc+AbgWaAL22m2O5lXXutzOZyPVjohEXmlFE798aiO+QIiLThjJD44fZXZIchAiWba4HdB3gUUGmYamAPOf3EBFnY9jC4bw8/MnmR2SHCR99V8kjgWDIe58roSSPQ2MG5bKfT+epnO0DGJK6CJx7Pdv7+Qf6yvJSrOy5OrpZKfrHC2DmRK6SJx6+5P9PPXObqwWuO/yaUwYkWZ2SHKIlNBF4tD67bXcG65o+fn5E/lW4VCTI5JIUEIXiTNllU3Mf3IjXn+I7x83kotOUEVLrFBCF4kjjU0Bbl6+gYpaH0dPzWb+BRNJSNCHoLFCCV0kTgSDIe56YTObwhUt918xjUSrUkAs0bMpEice/8tO3v28gsxUKw/Nmc6QdPPPdCqRpYQuEgf+8ukBlv11N5YE+PXlBUwcqYqWWKSELhLjvthRyz0vbAbgxu9O5LjpOSZHJP1FCV0khu2rbuIXT26kyR/ie98ewSUnqaIllimhi8QojzfA/OUbOVDj45tTsvnFBZNU0RLjlNBFYpBR0bKFDbvqGZOXwm+umEZSol7usU7PsEgMWvbXXbzzWTkZ4YqWoRmqaIkHSugiMeZvn5Xz+F92GRUtlxUweVS62SHJAFFCF4khxTvruOt5o6LlhvMmcHyRKlriiRK6SIzYX+1l/vINNPmCnHfscH5kyzc7JBlgSugiMcDjC/CLJzewv8bHkZOzuPXCyapoiUNK6CKDXCgU4t4XtvDlznryc1N44IpCVbTEKT3rIoPc8r/t5i//KSc9xcKSOdPJyVRFS7xSQhcZxN79vJz/9/ZOEhLgnsumMSVfFS3xTAldZJDauKueRc0VLd+ZwEkzVNES75TQRQahAzVebl6+AY83yHeOHs6ldlW0iBK6yKDT5Avyyyc3sq/ayxETs1hwkSpaxKCELjKIhEIh7n1xC+t31JGfk8IDVxaSrIoWCdNIEBlEnnpnN85PD5CWbGHxnEJys1TRIq2U0EUGib+vK+ex1eGKlksLKBidYXZIEmWU0EUGgU176ln0nFHRct0547HNzDU5IolGSugiUa681svNyzbQ6A1y9lHD+PEpo80OSaKUErpIFGuuaCmr8jJzQiYLL5qiihbpUmIkd2a3Oa4HrgQOB553uZ1XRnL/IvEkFApx38tbWLe9jpFDk3nwqkJSkjQHk65FNKEDe4B7AQeQFuF9i8SVFX/fw+pPDpCabOGhOdPJy0o2OySJchFN6C63848AdpvjaGBsT9sHAgECgUAkQ+iT5rbNjCFaqC9aBYPBlluz+mPNF5U8+tYOAO6cPZkpo1JNiUXjolU09EVPbUd6ht4nxcXFJCebX0dbXFxsdghRQ30BFRUVAJSUlFBeXj7g7e+qDPKb1R5CIfjeN5IYxh7Wr98z4HG0pXHRysy+8Hp93a43NaEXFRWRlpZqWvuBQIDi4mKKioqwWq2mxREN1BetSktLASgoKCA/f2DPkVJR5+P2VV/Q5AfHN/L45Wxzv9avcdEqGvqisdEDvNHlelMTutVqjYpBEi1xRAP1BVgslpbbgewLrz/IwhWb2Vvp5bDxmdx2yVQSo+Rr/RoXrczsi57ajY7RIhLnQqEQv3nlKz7bVsuIIapokYMT6bLFxPA+rYDVbnOkAn6X2+mPZDsiseZZVylvfrSflCTjHC3DslXRIn0X6SnAbUAjcCtwWfj32yLchkhMWfNlJY/8eTsAd/1oKtPHZpockQxWkS5bXAQsiuQ+RWLZltIGbn9mE6EQXHvWOE6dlWd2SDKI6SCdiEkq63zctHwDDU1BzjwyjzmnjzE7JBnklNBFTODzB7n16Y2UVjQxY1wGt83WOVrk0CmhiwywUCjEA69u5dOvahmencSDV00nNUklgXLolNBFBtjz7lLe+HAfKUkWHpwzneFDVNEikaGELjKA1hZX8r+rjIqWO2ZPYcY4VbRI5CihiwyQr/Y28KtnSgiGYO6ZYznjyGFmhyQxRgldZABU1fm4efkG6j0BTjsij7ln9HgyUpE+U0IX6Wc+f5BbV2xid3kT08dmcOfsKVgsqmiRyFNCF+lHoVCIB1/byr+31DAsO4nFcwpJTVZFi/QPJXSRfvTimr386Z/7SElMYPFV0xkxJMXskCSGKaGL9JMPNlTyP29sA+D22VOZMV4VLdK/lNBF+sG2skYWrjQqWq4+YwxnfkMVLdL/lNBFIqy6obWi5dRZuVxz5jizQ5I4oYQuEkH+QJAFT29i5wEPhWMyuHP2VFW0yIBRQheJkFAoxOLXtvHx5hpys5JYfFUhaSmqaJGBo4QuEiEvv7+XP35QRnJiAouvKmRkjipaZGApoYtEwL82VvHw69sAuO2SKcyckGVuQBKXlNBFDtH2fY0sWLGJQBCuPG0MZ31zuNkhSZxSQhc5BNUNPm5atoE6TwD74bn85CxVtIh5lNBFDpI/EGThihJ2HvBQMDqdRT9URYuYSwld5CAt+dM2PiqpJjcriYfmTCddFS1iMiV0kYPwyvt7eWVtGUnWBH57ZSGjVNEiUUAJXaSPPtxUxUN/2goYFS2zJqqiRaKDErpIH2zf31rRcsWpozn7KFW0SPRQQhfppZoGPzcv20BtYwDbYTn89OzxZock0o4Sukgv+AMhFq7YxI79Hqbmp3P3pQWqaJGoo4Qu0gsPv76ND0uqyclMVEWLRC0ldJEevLp2Ly+/v7eloiU/VxUtEp2U0EW68VFJNYtfMypaFlw0mSMmZZsckUjXEs0OQCRa7SlvYsGLuwgE4TL7aM49ZoTZIYl0SzN0kS7c89JX1DQGOHFGDvO+o4oWiX4RnaHbbY5cYBlwJnAAWOByO5+LZBsi/S0QDAGwu7yJgkl53HNpAVZVtMggEOkZ+lLAC4wELgUes9sch0W4DZF+tfyvuwHITrfy0NXTyUhVRYsMDhGbodttjgzgQmCmy+2sA96z2xxvAJcDt3Z2n9K9paSmmFcxEAwGqaiooLS0FIslvo8+qS8Mb/+7nNfXbAHg2lOzwFPBnj0mB2UijYtW0dAXnqambtdH8pDLNCDgcjs3tVn2GXByV3c4+6yz8ft9EQxBJHIW3nC52SGItJOYmMTp513c9foItpUJVHdYVg10eeai1W+vNn2GXlJSQkFBgWYfcd4XJXsaWLhyM02+II7DLLywZB6vvvoqI0bEd2VLvI+LtqKhLzxNTTy09Mku10cyodcBHYt0s4Haru6QPyqftLTUCIbQN4FAgPLycvLz87Fa4/s4aTz3xY79jdy3aje+xCF851vD+K+T03lhCYwYMYLRo0ebHZ6p4nlcdBQNfdHY6Ol2fST/zWwCEu02R0GbZUcAX0SwDZGIOlDj5WePF1NZ5+fbhUO4/ZIpJCSookUGp4gldJfbWQ/8EbjbbnNk2G2OE4DzgZWRakMkksprvVz32JfsLm9i+tgMfnNFIYnW+D6sIINbpEfvdUAasA94Hvipy+3UDF2iTkWtj+se+5Jt+xqZMiqN311TpBNuyaAX0S8WudzOCuB7kdynSKRV1vmY9/sv2FrWyORRaSz9yWHkZCaZHZbIIdO5XCSulFU18d9/KGZrWSOTRqax9CczyM1SMpfYoIQucWNrWQP//Ydiyqq8TBmVxiPXziAvK9nssEQiRgld4sL67bXc+MQGahr8HDExi4eunk52uoa/xBaNaIl5735ezqLnN+PxBjmhaCj3/3gaqcn6AFRijxK6xKxgMMSyv+7i8b/sAuC8Y4az4KLJKk2UmKWELjGpsSnA3S9u4Z3PyklIgP8+dwI/OjlfXxqSmKaELjFny94GFq7YxNayRjJSrdx7WQEnFOWYHZZIv1NCl5gRCoVY9eF+HnxtK02+IJNGpvGbK6YxaWS62aGJDAgldIkJ1Q0+Fv9xG85PDwBw7jHD+cUFk0jTtz8ljiihy6D33peV3PfyFg7U+EhNtnDLhZP5ztHDzQ5LZMApocugVVXv45FV21n10X4AjpiYxR0/nMK4YWkmRyZiDiV0GXSCwRB//ng/j7y5nap6P8mJCfz0nPHMPilfF3OWuKaELoPKxl31LH5tK59tM66bctTUbG75/mQmjtSsXEQJXQaFssomHl29g9WfGB965mYlceN3J+D4xjDVlouEKaFLVKus8/GMaw8vrSmlyR8iyZrARSeO4uozxpKVpuEr0pZeERKVKut8POvaw8vv76XRGwTgjCPzuO6c8YzJM+86tCLRTAldosr2/Y286C7lzY/34wkn8hOKhnLNmeOYMT7T5OhEopsSupguFArxUUkNL6wp5b0vK1uWK5GL9I0Supimqt6H898HeP1f+9hc2gBAcmICZx81nNm2fKaM0lf2RfpCCV0GlD8Q4l+bqlj14T7WfFGJLxACjKqVi04YxfePG6nre4ocJCV06XeBYIjPttbw7ucVvPt5OQdqfABYEuC46UM595jhnDwzl+REnadc5FAooUu/8PmD/HtLDe+uq+Af6yqoqPO1rBs3LJXzjh3BOUcPY8SQFBOjFIktSugSMbsOePjnxio+2FDFx5urW8oNAcbmpXDKrDxOnZXLjHGZ+jKQSD9QQpeDVlrRxKdf1fDpVzV8srmaXeVN7dZPGZXGyTNzOXVWHgWj05XERfqZErr0iscbYNOeBop31vHFjjr+s7WGvZXedttkpVk5dtpQjiscyrcKhzByqA6niAwkJXT5mjqPn61ljWzYWc+GXXUU76pna1kDgWD77bLSrBw5KZsjJ2fxjcnZTB+bSaJVs3ARsyihx7GaBj/b9jWytayBLaX1rNviYf/r/2Fftfdr21otMDU/naKxGRSNy+SISVlMGZWORaerFYkaSugxzOcPsreqid3lTewu97C7vIk9FZ6Wv+s8gU7u5SU5MYHxw9MoHJPB9HACnzY6ndRkXc5NJJopoQ9CXn+Q6no/lXU+9lV7OVDjZX/41vjbx/4aL5V1PkKhrveTlmxh3LBUJo9KZ8KIVKyefdiPmc7Y4ek6dCIyCCmhmyQUCtHoDVLn8VPvCVDvCVAXvq1t9FNV76eq3kdVvZ/qeh+Vdc2/+6lv6mxm/XWWBBiVk8LovBTG5Ka23I7JS2FMXipDMxJbKk8CgQDr11cwbngqViVzkUEpIgndbnNcD1wJHA4873I7r4zEfs0QCoUIBMEfCOILhPD5Q/gCQXz+EB5fAI83SJMviMcX7PB7AI8v/Le3dVnz30bCNpJxXWOAhqYAwW5mz92xWmBIRhI5GYkMH5LM8Oxkhg1Jbvl9eLbxe05mkmbaInEkUjP0PcC9gAPo9bXAXv+wDIs1mWAQAqEQwWCoy98DQeMr5ME2fwdDIWNZF783J2Z/IIQvEDJu/cF2vzc2eQm98gn+5mWBULeHKSIpNdlCRoqVzFQrGalWMlITyUy1kplmJScjiaEZSQzNSGRIpnFr/CSRmWpVTbeIfE1EErrL7fwjgN3mOBoY29v7PfziZwSaQ0gAS2oOoWCAUFNNu+0SkjNIsCYTbKqBYJvDDdYkLMmZhPweQr7G9vdJHQqECHmq2y9PSichMYWgtxYC/tYVlkQsKVmEAl4S/PUkWi0kWiHRkkBKRg4pyYlYvFUkJ1lISUwgJclCZmYmGRkZJPjrseIjJclCcqKFtJQkhg3Lw4ofn6eWlCQLGamJpCdbGDNqGNmZqTSzZ7heAAAJiUlEQVTUlNO2QCQ9PZ2srCxqa2tpaGhoDcsSZPjwbHw+HxUVFdR6oTa8Licnh+TkZMrLy/H7Wx9LamoqQ4YMob6+nrq6unaPf+TIkQQCAQ4cONBueWamcYraAwcOEAi09nFycjI5OTk0NjZSU9P+eRk+fDgJCQns27ev3fKsrCzS09Opqqqiqan1y0ZJSUnk5ubS1NREVVVVu/vk5eWRmJjIvn37CLX5j5qRkUFmZiY1NTU0NrY+x1arlWHDhuH1eqmsrGy3r+Z+6fhY0tLSyM7Opq6ujvr6+pblCQkJjBgxAr/fT3l5ecvj2bdvH0OHDiUlJYWKigp8vtbTF6SkpDB06FAaGhqora2lrREjRhAKhdi/f3+75dnZ2aSlpVFZWYnX21pJ1NwvHo+H6ur243XYsGFYrVbKysraLW8ee9XV1Xg8npbliYmJ5OXlddovubm5JCUlsX//foLB1hrUrseehdzcXPx+P6WlpVgsrefaieTYGzJkCKmpqV/r42gbe8FgkIqKCsrKyhg5cmS/jL22Oht7nqb2X97ryNRj6FXv/BK/3wg0KSWNH9z8JHWVB1j12I3ttjvjR79k4vSjeP0PS9i3a3PL8oJZx3HupT/ns7Xv8u6by9vdZ8Hi5wj4vPx2wQ3tlv/wyus43nYqf/jdw6z77JOW5Ycddjh3LFrEP9f+m4cfXtLuPk888QS5ublcdNFP2j1Jl19+ORdccAGPPLKUv//97y3LJ0yYwMMPP8znn3/OokWL2u1ryZIlTJw4kauvvrrdYPje977Hj3/8Y1asWMGf/vSnluU5OTksW7aMbdu2cdNNN7Xb16JFi5g1axY///nP2b59e8vyU045hRtuuIHXXnuNlStXtiy3Wq28/PLLVFRUMHfu3Hb7uummmzjxxBO59tprWbduXcvyo48+moULF/LOO++wdOnSdvdZuXIlKSkpXHzxxe2Wz507l3POOYfFixezdu3aluUFBQU88MADfPTRR9x///3t7rN06VLy8/O57LLL2iWViy++mNmzZ/P444+zevXqluWjRo3i0UcfZePGjSxYsKDdvu6//34KCwu57rrr2Lt3b8vys88+m2uuuYYXXniBl156qWV5eno6zzzzDKWlpcybN69l+YUXXsiCBQs45phjuOWWWygpKWlZd/zxxzN//nzeeustnnjiiXbtv/TSSzQ1NXH55Ze3Wz5v3jxOO+007rvvPj7++OOW5Ycffjh33XUX7733HkuWdDX2Lupi7D3S72Nv165dX3uO+2Ps3XnnnRp7bXQ29hITkzj9vPaPua2EUASPL9htjnuBsT0dQ583/44hQNXN864iNcX4NmFf/1PBoc+SPB4PJSUlFBQUkJKSErWzpOHDh7fM0NuK9Ax969atjBo1SjP0ffu48MILefXVV5k2bVrcz9DXrVvHyJEjNUMPBikpKaGwsNDUGfpDS58EGLp08d3tBwu9SOh2m8MFnNzF6vddbueJbbbtU0JffM9C0tLMuz6kUdmxnpkzZ2K1xneNtfqi1Z49ezjppJNYs2YNo0ePNjscU2lctIqGvmhs9DD/9vugi4Te4yEXl9tp74e4REQkwiJVtpgY3pcVsNptjlTA73I7/d3fU0REIiVSl4i5DWgEbgUuC/9+W4T2LSIivRCpssVFwKJI7EtERA6OLuIoIhIjlNBFRGKEErqISIxQQhcRiRFK6CIiMUIJXUQkRiihi4jECCV0EZEYoYQuIhIjlNBFRGKEErqISIxQQhcRiRFK6CIiMUIJXUQkRiihi4jECCV0EZEYoYQuIhIjlNBFRGKEErqISIxQQhcRiRFK6CIiMUIJXUQkRiihi4jECCV0EZEYoYQuIhIjlNBFRGKEErqISIxQQhcRiRFK6CIiMUIJXUQkRiQe6g7sNkcK8ChwOpALbAYWutzO1Ye6bxER6b1IzNATgZ3AycAQ4HbgJbvNMTEC+xYRkV465Bm6y+2sBxa1WfSm3ebYChwFbOvuvoFAgEAgcKghHLTmts2MIVqoL1oFg8GW23jvD42LVtHQFz21fcgJvSO7zTESmAZ80dO2xcXFJCcnRTqEPisuLjY7hKihvoCKigoASkpKKC8vNzma6KBx0crMvvB6fd2uj2hCt9scScCzwNMut3NDT9sXFRWRlpYayRD6JBAIUFxcTFFREVar1bQ4ooH6olVpaSkABQUF5OfnmxyNuTQuWkVDXzQ2eoA3ulzfY0K32xwujOPjnXnf5XaeGN7OAqwEvMD1vQnOarVGxSCJljiigfoCLBZLy22890UzjYtWZvZFT+32mNBdbqe9p23sNkcCsAwYCZzjcju7f18gIiIRF6lDLo8BRcDpLrezMUL7FBGRPohEHfoE4FqgCdhrtzmaV13rcjufPdT9i4hI70SibHE7kBCBWERE5BBEvGyxLxo9HjObJxAI4PX6aGz0xP0HPuqLVp6mJhITk/A0NYWrCuKXxkWraOiLnnJmQigUGqBQWs2bf8c4YMeANywiEhvGL118986OC82aoe8CxgM1JrUvIjJYZWPk0K8xZYYuIiKRp9PniojECCV0EZEYoYQuIhIjlNBFRGKEErqISIww9YtF0cZucxQA64BXXG7nZWbHM9B0OUGw2xy5GCeaOxM4ACxwuZ3PmRvVwNNY6Fy05wjN0NtbCnxkdhAm0uUEjTHgxThz6KXAY3ab4zBzQzKFxkLnojpHaIYeZrc5ZgNVwFpgqsnhmOJQLicYC+w2RwZwITDT5XbWAe/ZbY43gMuBW00NboDF+1jozGDIEZqhA3abIxu4G7jZ7FiiSV8uJxgjpgEBl9u5qc2yz4B4nKG3E4djoZ3BkiOU0A33AMtcbufXzo0Qr/p6OcEYkQlUd1hWDWSZEEvUiNOx0NGgyBExf8ilp0voYVwu73TgGwMVk1n683KCMaIO4zwZbWUDtSbEEhXieCy0sNscRzJIckTcn8vFbnPcCPya1hdtJmAFil1u5zdNC8wk4csJLgcmYlxOMG6uQBU+hl4JHOZyO0vCy1YAe1xuZ1wdQ4f4HgttDaYcEfMz9F74A/BCm7/nYwzgn5oSjfni9nKCLrez3m5z/BG4225zzAWOBM4Hjjc3MtPE7VjoYNDkiLifoXdktzkWAVOjsca0v4UvJ7gN43KC/jar4uZyguE69OXAGUA5cGuc1qHH/VjoSjTnCCV0EZEYoSoXEZEYoYQuIhIjlNBFRGKEErqISIxQQhcRiRFK6CIiMUIJXUQkRiihi4jEiP8P8vitzrqpvyEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "#save_fig(\"elu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing ELU in TensorFlow is trivial, just specify the activation function when building each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:18:29.124254Z",
     "start_time": "2019-05-10T14:18:29.119466Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:18:29.143820Z",
     "start_time": "2019-05-10T14:18:29.126319Z"
    }
   },
   "outputs": [],
   "source": [
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.elu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SELU**   \n",
    "\n",
    "This activation function was proposed in this (great paper)[https://arxiv.org/pdf/1706.02515.pdf] by Günter Klambauer, Thomas Unterthiner and Andreas Mayr, published in June 2017. During training, a neural network composed exclusively of a stack of dense layers using the SELU activation function and LeCun initialization will self-normalize: the output of each layer will tend to preserve the same mean and variance during training, which solves the vanishing/exploding gradients problem. As a result, this activation function outperforms the other activation functions very significantly for such neural nets, so you should really try it out. Unfortunately, the self-normalizing property of the SELU activation function is easily broken: you cannot use ℓ1 or ℓ2 regularization, regular dropout, max-norm, skip connections or other non-sequential topologies (so recurrent neural networks won't self-normalize). However, in practice it works quite well with sequential CNNs. If you break self-normalization, SELU will not necessarily outperform other activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:18:29.149093Z",
     "start_time": "2019-05-10T14:18:29.145232Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import erfc\n",
    "\n",
    "# alpha and scale to self normalize with mean 0 and standard deviation 1\n",
    "# (see equation 14 in the paper):\n",
    "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
    "scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:18:29.156766Z",
     "start_time": "2019-05-10T14:18:29.150428Z"
    }
   },
   "outputs": [],
   "source": [
    "def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
    "    return scale * elu(z, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:18:29.241217Z",
     "start_time": "2019-05-10T14:18:29.158190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"SELU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "#save_fig(\"selu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "By default, the SELU hyperparameters (scale and alpha) are tuned in such a way that the mean output of each neuron remains close to 0, and the standard deviation remains close to 1 (assuming the inputs are standardized with mean 0 and standard deviation 1 too). Using this activation function, even a 1,000 layer deep neural network preserves roughly mean 0 and standard deviation 1 across all layers, avoiding the exploding/vanishing gradients problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:18:30.496452Z",
     "start_time": "2019-05-10T14:18:29.242777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: mean -0.00, std deviation 1.00\n",
      "Layer 100: mean 0.02, std deviation 0.96\n",
      "Layer 200: mean 0.01, std deviation 0.90\n",
      "Layer 300: mean -0.02, std deviation 0.92\n",
      "Layer 400: mean 0.05, std deviation 0.89\n",
      "Layer 500: mean 0.01, std deviation 0.93\n",
      "Layer 600: mean 0.02, std deviation 0.92\n",
      "Layer 700: mean -0.02, std deviation 0.90\n",
      "Layer 800: mean 0.05, std deviation 0.83\n",
      "Layer 900: mean 0.02, std deviation 1.00\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "Z = np.random.normal(size=(500, 100)) # standardized inputs\n",
    "for layer in range(1000):\n",
    "    W = np.random.normal(size=(100, 100), scale=np.sqrt(1 / 100)) # LeCun initialization\n",
    "    Z = selu(np.dot(Z, W))\n",
    "    means = np.mean(Z, axis=0).mean()\n",
    "    stds = np.std(Z, axis=0).mean()\n",
    "    if layer % 100 == 0:\n",
    "        print(\"Layer {}: mean {:.2f}, std deviation {:.2f}\".format(layer, means, stds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf.nn.selu() function was added in TensorFlow 1.4. For earlier versions, you can use the following implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:18:30.500455Z",
     "start_time": "2019-05-10T14:18:30.497991Z"
    }
   },
   "outputs": [],
   "source": [
    "def selu(z, scale=alpha_0_1, alpha=scale_0_1):\n",
    "    return scale * tf.where(z >= 0.0, z, alpha * tf.nn.elu(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the SELU activation function cannot be used along with regular Dropout (this would cancel the SELU activation function's self-normalizing property). Fortunately, there is a Dropout variant called Alpha Dropout proposed in the same paper. It is available in tf.contrib.nn.alpha_dropout() since TF 1.4 (or check out this implementation[https://github.com/bioinf-jku/SNNs/blob/master/selu.py] by the Institute of Bioinformatics, Johannes Kepler University Linz).\n",
    "\n",
    "Let's create a neural net for MNIST using the SELU activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:18:30.733624Z",
     "start_time": "2019-05-10T14:18:30.501812Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=selu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=selu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train it. Do not forget to scale the inputs to mean 0 and standard deviation 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:20:13.853207Z",
     "start_time": "2019-05-10T14:18:30.735719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.94 Validation accuracy: 0.9388\n",
      "5 Batch accuracy: 0.98 Validation accuracy: 0.9634\n",
      "10 Batch accuracy: 1.0 Validation accuracy: 0.9694\n",
      "15 Batch accuracy: 1.0 Validation accuracy: 0.9704\n",
      "20 Batch accuracy: 1.0 Validation accuracy: 0.9692\n",
      "25 Batch accuracy: 1.0 Validation accuracy: 0.9692\n",
      "30 Batch accuracy: 1.0 Validation accuracy: 0.9708\n",
      "35 Batch accuracy: 1.0 Validation accuracy: 0.9704\n"
     ]
    }
   ],
   "source": [
    "means = X_train.mean(axis=0, keepdims=True)\n",
    "stds = X_train.std(axis=0, keepdims=True) + 1e-10\n",
    "X_val_scaled = (X_valid - means) / stds\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            X_batch_scaled = (X_batch - means) / stds\n",
    "            sess.run(training_op, feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_val_scaled, y: y_valid})\n",
    "            print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final_selu.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Batch Normalization**   \n",
    "\n",
    "It is now preferable to use tf.layers.batch_normalization(), because anything in the contrib module may change or be deleted without notice. Instead of using the batch_norm() function as a regularizer parameter to the fully_connected() function, we now use batch_normalization() and we explicitly create a distinct layer. The parameters are a bit different, in particular:\n",
    "\n",
    "decay is renamed to momentum,\n",
    "is_training is renamed to training,\n",
    "updates_collections is removed: the update operations needed by batch normalization are added to the UPDATE_OPS collection and you need to explicity run these operations during training (see the execution phase below),\n",
    "we don't need to specify scale=True, as that is the default.\n",
    "Also note that in order to run batch norm just before each hidden layer's activation function, we apply the ELU activation function manually, right after the batch norm layer.\n",
    "\n",
    "Note: since the tf.layers.dense() function is incompatible with tf.contrib.layers.arg_scope() (which is used in the book), we now use python's functools.partial() function instead. It makes it easy to create a my_dense_layer() function that just calls tf.layers.dense() with the desired parameters automatically set (unless they are overridden when calling my_dense_layer()). As you can see, the code remains very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:20:14.015851Z",
     "start_time": "2019-05-10T14:20:13.854638Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = tf.layers.batch_normalization(hidden1, training=training, momentum=0.9)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = tf.layers.batch_normalization(hidden2, training=training, momentum=0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training=training,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:20:14.022002Z",
     "start_time": "2019-05-10T14:20:14.017108Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid repeating the same parameters over and over again, we can use Python's partial() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:20:14.179406Z",
     "start_time": "2019-05-10T14:20:14.023632Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "my_batch_norm_layer = partial(tf.layers.batch_normalization,\n",
    "                              training=training, momentum=0.9)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = my_batch_norm_layer(hidden1)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = my_batch_norm_layer(hidden2)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = my_batch_norm_layer(logits_before_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a neural net for MNIST, using the ELU activation function and Batch Normalization at each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:20:14.632590Z",
     "start_time": "2019-05-10T14:20:14.180876Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "batch_norm_momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    he_init = tf.variance_scaling_initializer()\n",
    "\n",
    "    my_batch_norm_layer = partial(\n",
    "            tf.layers.batch_normalization,\n",
    "            training=training,\n",
    "            momentum=batch_norm_momentum)\n",
    "\n",
    "    my_dense_layer = partial(\n",
    "            tf.layers.dense,\n",
    "            kernel_initializer=he_init)\n",
    "\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1))\n",
    "    hidden2 = my_dense_layer(bn1, n_hidden2, name=\"hidden2\")\n",
    "    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2))\n",
    "    logits_before_bn = my_dense_layer(bn2, n_outputs, name=\"outputs\")\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to explicitly run the extra update operations needed by batch normalization (sess.run([training_op, extra_update_ops],...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:20:14.636197Z",
     "start_time": "2019-05-10T14:20:14.634129Z"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:20:44.971669Z",
     "start_time": "2019-05-10T14:20:14.637832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.8952\n",
      "1 Validation accuracy: 0.9202\n",
      "2 Validation accuracy: 0.9318\n",
      "3 Validation accuracy: 0.9422\n",
      "4 Validation accuracy: 0.9468\n",
      "5 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.9568\n",
      "7 Validation accuracy: 0.96\n",
      "8 Validation accuracy: 0.962\n",
      "9 Validation accuracy: 0.9638\n",
      "10 Validation accuracy: 0.9662\n",
      "11 Validation accuracy: 0.9682\n",
      "12 Validation accuracy: 0.9672\n",
      "13 Validation accuracy: 0.9696\n",
      "14 Validation accuracy: 0.9706\n",
      "15 Validation accuracy: 0.9704\n",
      "16 Validation accuracy: 0.9718\n",
      "17 Validation accuracy: 0.9726\n",
      "18 Validation accuracy: 0.9738\n",
      "19 Validation accuracy: 0.9742\n"
     ]
    }
   ],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run([training_op, extra_update_ops],\n",
    "                     feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing: notice that the list of trainable variables is shorter than the list of all global variables. This is because the moving averages are non-trainable variables. If you want to reuse a pretrained neural network (see below), you must not forget these non-trainable variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:20:44.980313Z",
     "start_time": "2019-05-10T14:20:44.975373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'outputs/kernel:0',\n",
       " 'outputs/bias:0',\n",
       " 'batch_normalization_2/gamma:0',\n",
       " 'batch_normalization_2/beta:0']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tf.trainable_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:20:44.989943Z",
     "start_time": "2019-05-10T14:20:44.981542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'batch_normalization/moving_mean:0',\n",
       " 'batch_normalization/moving_variance:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'batch_normalization_1/moving_mean:0',\n",
       " 'batch_normalization_1/moving_variance:0',\n",
       " 'outputs/kernel:0',\n",
       " 'outputs/bias:0',\n",
       " 'batch_normalization_2/gamma:0',\n",
       " 'batch_normalization_2/beta:0',\n",
       " 'batch_normalization_2/moving_mean:0',\n",
       " 'batch_normalization_2/moving_variance:0']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tf.global_variables()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Gradient Clipping**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple neural net for MNIST and add gradient clipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:20:45.089206Z",
     "start_time": "2019-05-10T14:20:44.991816Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_hidden5 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:20:45.095010Z",
     "start_time": "2019-05-10T14:20:45.091416Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply gradient clipping. For this, we need to get the gradients, use the clip_by_value() function to clip them, then apply them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:20:45.227710Z",
     "start_time": "2019-05-10T14:20:45.098307Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)\n",
    "              for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:20:45.236216Z",
     "start_time": "2019-05-10T14:20:45.229745Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:20:45.259956Z",
     "start_time": "2019-05-10T14:20:45.237748Z"
    }
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:20:45.265305Z",
     "start_time": "2019-05-10T14:20:45.262240Z"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:21:09.374424Z",
     "start_time": "2019-05-10T14:20:45.266737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.288\n",
      "1 Validation accuracy: 0.7938\n",
      "2 Validation accuracy: 0.8798\n",
      "3 Validation accuracy: 0.906\n",
      "4 Validation accuracy: 0.9164\n",
      "5 Validation accuracy: 0.9222\n",
      "6 Validation accuracy: 0.9292\n",
      "7 Validation accuracy: 0.9358\n",
      "8 Validation accuracy: 0.9382\n",
      "9 Validation accuracy: 0.9414\n",
      "10 Validation accuracy: 0.9456\n",
      "11 Validation accuracy: 0.9472\n",
      "12 Validation accuracy: 0.9476\n",
      "13 Validation accuracy: 0.9534\n",
      "14 Validation accuracy: 0.9568\n",
      "15 Validation accuracy: 0.9566\n",
      "16 Validation accuracy: 0.9578\n",
      "17 Validation accuracy: 0.9588\n",
      "18 Validation accuracy: 0.9624\n",
      "19 Validation accuracy: 0.9612\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reusing Pretrained Layers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Reusing a TensorFlow Model**\n",
    "First you need to load the graph's structure. The import_meta_graph() function does just that, loading the graph's operations into the default graph, and returning a Saver that you can then use to restore the model's state. Note that by default, a Saver saves the structure of the graph into a .meta file, so that's the file you should load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:23:32.920119Z",
     "start_time": "2019-05-10T14:23:32.917749Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:23:38.870252Z",
     "start_time": "2019-05-10T14:23:38.832836Z"
    }
   },
   "outputs": [],
   "source": [
    "saver = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you need to get a handle on all the operations you will need for training. If you don't know the graph's structure, you can list all the operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T14:27:13.568137Z",
     "start_time": "2019-05-10T14:27:13.559242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "y\n",
      "hidden1/kernel/Initializer/random_uniform/shape\n",
      "hidden1/kernel/Initializer/random_uniform/min\n",
      "hidden1/kernel/Initializer/random_uniform/max\n",
      "hidden1/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden1/kernel/Initializer/random_uniform/sub\n",
      "hidden1/kernel/Initializer/random_uniform/mul\n",
      "hidden1/kernel/Initializer/random_uniform\n",
      "hidden1/kernel\n",
      "hidden1/kernel/Assign\n",
      "hidden1/kernel/read\n",
      "hidden1/bias/Initializer/zeros\n",
      "hidden1/bias\n",
      "hidden1/bias/Assign\n",
      "hidden1/bias/read\n",
      "dnn/hidden1/MatMul\n",
      "dnn/hidden1/BiasAdd\n",
      "dnn/hidden1/Relu\n",
      "hidden2/kernel/Initializer/random_uniform/shape\n",
      "hidden2/kernel/Initializer/random_uniform/min\n",
      "hidden2/kernel/Initializer/random_uniform/max\n",
      "hidden2/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden2/kernel/Initializer/random_uniform/sub\n",
      "hidden2/kernel/Initializer/random_uniform/mul\n",
      "hidden2/kernel/Initializer/random_uniform\n",
      "hidden2/kernel\n",
      "hidden2/kernel/Assign\n",
      "hidden2/kernel/read\n",
      "hidden2/bias/Initializer/zeros\n",
      "hidden2/bias\n",
      "hidden2/bias/Assign\n",
      "hidden2/bias/read\n",
      "dnn/hidden2/MatMul\n",
      "dnn/hidden2/BiasAdd\n",
      "dnn/hidden2/Relu\n",
      "hidden3/kernel/Initializer/random_uniform/shape\n",
      "hidden3/kernel/Initializer/random_uniform/min\n",
      "hidden3/kernel/Initializer/random_uniform/max\n",
      "hidden3/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden3/kernel/Initializer/random_uniform/sub\n",
      "hidden3/kernel/Initializer/random_uniform/mul\n",
      "hidden3/kernel/Initializer/random_uniform\n",
      "hidden3/kernel\n",
      "hidden3/kernel/Assign\n",
      "hidden3/kernel/read\n",
      "hidden3/bias/Initializer/zeros\n",
      "hidden3/bias\n",
      "hidden3/bias/Assign\n",
      "hidden3/bias/read\n",
      "dnn/hidden3/MatMul\n",
      "dnn/hidden3/BiasAdd\n",
      "dnn/hidden3/Relu\n",
      "hidden4/kernel/Initializer/random_uniform/shape\n",
      "hidden4/kernel/Initializer/random_uniform/min\n",
      "hidden4/kernel/Initializer/random_uniform/max\n",
      "hidden4/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden4/kernel/Initializer/random_uniform/sub\n",
      "hidden4/kernel/Initializer/random_uniform/mul\n",
      "hidden4/kernel/Initializer/random_uniform\n",
      "hidden4/kernel\n",
      "hidden4/kernel/Assign\n",
      "hidden4/kernel/read\n",
      "hidden4/bias/Initializer/zeros\n",
      "hidden4/bias\n",
      "hidden4/bias/Assign\n",
      "hidden4/bias/read\n",
      "dnn/hidden4/MatMul\n",
      "dnn/hidden4/BiasAdd\n",
      "dnn/hidden4/Relu\n",
      "hidden5/kernel/Initializer/random_uniform/shape\n",
      "hidden5/kernel/Initializer/random_uniform/min\n",
      "hidden5/kernel/Initializer/random_uniform/max\n",
      "hidden5/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden5/kernel/Initializer/random_uniform/sub\n",
      "hidden5/kernel/Initializer/random_uniform/mul\n",
      "hidden5/kernel/Initializer/random_uniform\n",
      "hidden5/kernel\n",
      "hidden5/kernel/Assign\n",
      "hidden5/kernel/read\n",
      "hidden5/bias/Initializer/zeros\n",
      "hidden5/bias\n",
      "hidden5/bias/Assign\n",
      "hidden5/bias/read\n",
      "dnn/hidden5/MatMul\n",
      "dnn/hidden5/BiasAdd\n",
      "dnn/hidden5/Relu\n",
      "outputs/kernel/Initializer/random_uniform/shape\n",
      "outputs/kernel/Initializer/random_uniform/min\n",
      "outputs/kernel/Initializer/random_uniform/max\n",
      "outputs/kernel/Initializer/random_uniform/RandomUniform\n",
      "outputs/kernel/Initializer/random_uniform/sub\n",
      "outputs/kernel/Initializer/random_uniform/mul\n",
      "outputs/kernel/Initializer/random_uniform\n",
      "outputs/kernel\n",
      "outputs/kernel/Assign\n",
      "outputs/kernel/read\n",
      "outputs/bias/Initializer/zeros\n",
      "outputs/bias\n",
      "outputs/bias/Assign\n",
      "outputs/bias/read\n",
      "dnn/outputs/MatMul\n",
      "dnn/outputs/BiasAdd\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/Shape\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\n",
      "loss/Const\n",
      "loss/loss\n",
      "gradients/Shape\n",
      "gradients/grad_ys_0\n",
      "gradients/Fill\n",
      "gradients/loss/loss_grad/Reshape/shape\n",
      "gradients/loss/loss_grad/Reshape\n",
      "gradients/loss/loss_grad/Shape\n",
      "gradients/loss/loss_grad/Tile\n",
      "gradients/loss/loss_grad/Shape_1\n",
      "gradients/loss/loss_grad/Shape_2\n",
      "gradients/loss/loss_grad/Const\n",
      "gradients/loss/loss_grad/Prod\n",
      "gradients/loss/loss_grad/Const_1\n",
      "gradients/loss/loss_grad/Prod_1\n",
      "gradients/loss/loss_grad/Maximum/y\n",
      "gradients/loss/loss_grad/Maximum\n",
      "gradients/loss/loss_grad/floordiv\n",
      "gradients/loss/loss_grad/Cast\n",
      "gradients/loss/loss_grad/truediv\n",
      "gradients/zeros_like\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul\n",
      "gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul_1\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden5/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden4/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden3/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden2/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden1/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1\n",
      "clip_by_value/Minimum/y\n",
      "clip_by_value/Minimum\n",
      "clip_by_value/y\n",
      "clip_by_value\n",
      "clip_by_value_1/Minimum/y\n",
      "clip_by_value_1/Minimum\n",
      "clip_by_value_1/y\n",
      "clip_by_value_1\n",
      "clip_by_value_2/Minimum/y\n",
      "clip_by_value_2/Minimum\n",
      "clip_by_value_2/y\n",
      "clip_by_value_2\n",
      "clip_by_value_3/Minimum/y\n",
      "clip_by_value_3/Minimum\n",
      "clip_by_value_3/y\n",
      "clip_by_value_3\n",
      "clip_by_value_4/Minimum/y\n",
      "clip_by_value_4/Minimum\n",
      "clip_by_value_4/y\n",
      "clip_by_value_4\n",
      "clip_by_value_5/Minimum/y\n",
      "clip_by_value_5/Minimum\n",
      "clip_by_value_5/y\n",
      "clip_by_value_5\n",
      "clip_by_value_6/Minimum/y\n",
      "clip_by_value_6/Minimum\n",
      "clip_by_value_6/y\n",
      "clip_by_value_6\n",
      "clip_by_value_7/Minimum/y\n",
      "clip_by_value_7/Minimum\n",
      "clip_by_value_7/y\n",
      "clip_by_value_7\n",
      "clip_by_value_8/Minimum/y\n",
      "clip_by_value_8/Minimum\n",
      "clip_by_value_8/y\n",
      "clip_by_value_8\n",
      "clip_by_value_9/Minimum/y\n",
      "clip_by_value_9/Minimum\n",
      "clip_by_value_9/y\n",
      "clip_by_value_9\n",
      "clip_by_value_10/Minimum/y\n",
      "clip_by_value_10/Minimum\n",
      "clip_by_value_10/y\n",
      "clip_by_value_10\n",
      "clip_by_value_11/Minimum/y\n",
      "clip_by_value_11/Minimum\n",
      "clip_by_value_11/y\n",
      "clip_by_value_11\n",
      "GradientDescent/learning_rate\n",
      "GradientDescent/update_hidden1/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden1/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden2/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden2/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden3/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden3/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden4/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden4/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden5/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden5/bias/ApplyGradientDescent\n",
      "GradientDescent/update_outputs/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_outputs/bias/ApplyGradientDescent\n",
      "GradientDescent\n",
      "eval/in_top_k/InTopKV2/k\n",
      "eval/in_top_k/InTopKV2\n",
      "eval/Cast\n",
      "eval/Const\n",
      "eval/accuracy\n",
      "init\n",
      "save/Const\n",
      "save/SaveV2/tensor_names\n",
      "save/SaveV2/shape_and_slices\n",
      "save/SaveV2\n",
      "save/control_dependency\n",
      "save/RestoreV2/tensor_names\n",
      "save/RestoreV2/shape_and_slices\n",
      "save/RestoreV2\n",
      "save/Assign\n",
      "save/Assign_1\n",
      "save/Assign_2\n",
      "save/Assign_3\n",
      "save/Assign_4\n",
      "save/Assign_5\n",
      "save/Assign_6\n",
      "save/Assign_7\n",
      "save/Assign_8\n",
      "save/Assign_9\n",
      "save/Assign_10\n",
      "save/Assign_11\n",
      "save/restore_all\n"
     ]
    }
   ],
   "source": [
    "for op in tf.get_default_graph().get_operations():\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:33:58.689314Z",
     "start_time": "2019-05-10T19:33:58.687220Z"
    }
   },
   "outputs": [],
   "source": [
    "#from tensorflow_graph_in_jupyter import show_graph\n",
    "#show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you know which operations you need, you can get a handle on them using the graph's get_operation_by_name() or get_tensor_by_name() methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:34:28.728069Z",
     "start_time": "2019-05-10T19:34:28.725581Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"eval/accuracy:0\")\n",
    "\n",
    "training_op = tf.get_default_graph().get_operation_by_name(\"GradientDescent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are the author of the original model, you could make things easier for people who will reuse your model by giving operations very clear names and documenting them. Another approach is to create a collection containing all the important operations that people will want to get a handle on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:35:02.394712Z",
     "start_time": "2019-05-10T19:35:02.392511Z"
    }
   },
   "outputs": [],
   "source": [
    "for op in (X, y, accuracy, training_op):\n",
    "    tf.add_to_collection(\"my_important_ops\", op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way people who reuse your model will be able to simply write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:35:14.193003Z",
     "start_time": "2019-05-10T19:35:14.191026Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y, accuracy, training_op = tf.get_collection(\"my_important_ops\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now you can start a session, restore the model's state and continue training on your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:35:23.847241Z",
     "start_time": "2019-05-10T19:35:23.831900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    # continue training the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:35:56.662446Z",
     "start_time": "2019-05-10T19:35:35.783652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Validation accuracy: 0.964\n",
      "1 Validation accuracy: 0.9626\n",
      "2 Validation accuracy: 0.965\n",
      "3 Validation accuracy: 0.965\n",
      "4 Validation accuracy: 0.9642\n",
      "5 Validation accuracy: 0.9646\n",
      "6 Validation accuracy: 0.9686\n",
      "7 Validation accuracy: 0.9684\n",
      "8 Validation accuracy: 0.9684\n",
      "9 Validation accuracy: 0.9684\n",
      "10 Validation accuracy: 0.9704\n",
      "11 Validation accuracy: 0.972\n",
      "12 Validation accuracy: 0.9672\n",
      "13 Validation accuracy: 0.9704\n",
      "14 Validation accuracy: 0.9712\n",
      "15 Validation accuracy: 0.9726\n",
      "16 Validation accuracy: 0.9718\n",
      "17 Validation accuracy: 0.9714\n",
      "18 Validation accuracy: 0.9712\n",
      "19 Validation accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if you have access to the Python code that built the original graph, you can use it instead of import_meta_graph():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:36:25.120599Z",
     "start_time": "2019-05-10T19:36:24.949705Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_hidden5 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)\n",
    "              for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:37:01.708445Z",
     "start_time": "2019-05-10T19:36:41.067297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Validation accuracy: 0.964\n",
      "1 Validation accuracy: 0.9626\n",
      "2 Validation accuracy: 0.965\n",
      "3 Validation accuracy: 0.965\n",
      "4 Validation accuracy: 0.9642\n",
      "5 Validation accuracy: 0.9646\n",
      "6 Validation accuracy: 0.9686\n",
      "7 Validation accuracy: 0.9684\n",
      "8 Validation accuracy: 0.9684\n",
      "9 Validation accuracy: 0.9684\n",
      "10 Validation accuracy: 0.9704\n",
      "11 Validation accuracy: 0.972\n",
      "12 Validation accuracy: 0.9672\n",
      "13 Validation accuracy: 0.9704\n",
      "14 Validation accuracy: 0.9712\n",
      "15 Validation accuracy: 0.9726\n",
      "16 Validation accuracy: 0.9718\n",
      "17 Validation accuracy: 0.9714\n",
      "18 Validation accuracy: 0.9712\n",
      "19 Validation accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general you will want to reuse only the lower layers. If you are using import_meta_graph() it will load the whole graph, but you can simply ignore the parts you do not need. In this example, we add a new 4th hidden layer on top of the pretrained 3rd layer (ignoring the old 4th hidden layer). We also build a new output layer, the loss for this new output, and a new optimizer to minimize it. We also need another saver to save the whole graph (containing both the entire old graph plus the new operations), and an initialization operation to initialize all the new variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:37:19.018727Z",
     "start_time": "2019-05-10T19:37:18.889330Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_hidden4 = 20  # new layer\n",
    "n_outputs = 10  # new layer\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "hidden3 = tf.get_default_graph().get_tensor_by_name(\"dnn/hidden3/Relu:0\")\n",
    "\n",
    "new_hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"new_hidden4\")\n",
    "new_logits = tf.layers.dense(new_hidden4, n_outputs, name=\"new_outputs\")\n",
    "\n",
    "with tf.name_scope(\"new_loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=new_logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"new_eval\"):\n",
    "    correct = tf.nn.in_top_k(new_logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"new_train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can train this new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:37:49.879054Z",
     "start_time": "2019-05-10T19:37:30.693617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Validation accuracy: 0.9116\n",
      "1 Validation accuracy: 0.9378\n",
      "2 Validation accuracy: 0.9462\n",
      "3 Validation accuracy: 0.9502\n",
      "4 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.9524\n",
      "6 Validation accuracy: 0.9566\n",
      "7 Validation accuracy: 0.96\n",
      "8 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.961\n",
      "10 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.963\n",
      "12 Validation accuracy: 0.965\n",
      "13 Validation accuracy: 0.9654\n",
      "14 Validation accuracy: 0.9664\n",
      "15 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.9678\n",
      "17 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.9684\n",
      "19 Validation accuracy: 0.968\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = new_saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If you have access to the Python code that built the original graph, you can just reuse the parts you need and drop the rest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:38:08.005250Z",
     "start_time": "2019-05-10T19:38:07.893448Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       # reused\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # reused\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # reused\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         # new!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you must create one Saver to restore the pretrained model (giving it the list of variables to restore, or else it will complain that the graphs don't match), and another Saver to save the new model, once it is trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:39:12.113059Z",
     "start_time": "2019-05-10T19:38:52.120792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Validation accuracy: 0.903\n",
      "1 Validation accuracy: 0.9328\n",
      "2 Validation accuracy: 0.9426\n",
      "3 Validation accuracy: 0.9472\n",
      "4 Validation accuracy: 0.952\n",
      "5 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.9556\n",
      "7 Validation accuracy: 0.959\n",
      "8 Validation accuracy: 0.9588\n",
      "9 Validation accuracy: 0.9606\n",
      "10 Validation accuracy: 0.9622\n",
      "11 Validation accuracy: 0.962\n",
      "12 Validation accuracy: 0.964\n",
      "13 Validation accuracy: 0.9656\n",
      "14 Validation accuracy: 0.9664\n",
      "15 Validation accuracy: 0.9662\n",
      "16 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.9672\n",
      "18 Validation accuracy: 0.9682\n",
      "19 Validation accuracy: 0.9672\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):                                            \n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size): \n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})        \n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})     \n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)                   \n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Freezing the Lower Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:39:43.797580Z",
     "start_time": "2019-05-10T19:39:43.733949Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       # reused\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # reused\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # reused\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         # new!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:39:56.978626Z",
     "start_time": "2019-05-10T19:39:56.941911Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with tf.name_scope(\"train\"):                                         \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)     \n",
    "    train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                   scope=\"hidden[34]|outputs\")\n",
    "    training_op = optimizer.minimize(loss, var_list=train_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:40:16.614349Z",
     "start_time": "2019-05-10T19:40:04.622452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Validation accuracy: 0.8956\n",
      "1 Validation accuracy: 0.9294\n",
      "2 Validation accuracy: 0.9398\n",
      "3 Validation accuracy: 0.9444\n",
      "4 Validation accuracy: 0.948\n",
      "5 Validation accuracy: 0.9508\n",
      "6 Validation accuracy: 0.9508\n",
      "7 Validation accuracy: 0.9532\n",
      "8 Validation accuracy: 0.9548\n",
      "9 Validation accuracy: 0.9566\n",
      "10 Validation accuracy: 0.956\n",
      "11 Validation accuracy: 0.9566\n",
      "12 Validation accuracy: 0.9568\n",
      "13 Validation accuracy: 0.9576\n",
      "14 Validation accuracy: 0.959\n",
      "15 Validation accuracy: 0.9582\n",
      "16 Validation accuracy: 0.9574\n",
      "17 Validation accuracy: 0.9606\n",
      "18 Validation accuracy: 0.9592\n",
      "19 Validation accuracy: 0.9602\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:40:19.889724Z",
     "start_time": "2019-05-10T19:40:19.885387Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:40:26.553686Z",
     "start_time": "2019-05-10T19:40:26.496127Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\") # reused frozen\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\") # reused frozen\n",
    "    hidden2_stop = tf.stop_gradient(hidden2)\n",
    "    hidden3 = tf.layers.dense(hidden2_stop, n_hidden3, activation=tf.nn.relu,\n",
    "                              name=\"hidden3\") # reused, not frozen\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu,\n",
    "                              name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\") # new!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:40:34.034257Z",
     "start_time": "2019-05-10T19:40:33.993718Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:40:51.386535Z",
     "start_time": "2019-05-10T19:40:39.183649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Validation accuracy: 0.9014\n",
      "1 Validation accuracy: 0.9308\n",
      "2 Validation accuracy: 0.9434\n",
      "3 Validation accuracy: 0.9476\n",
      "4 Validation accuracy: 0.9514\n",
      "5 Validation accuracy: 0.9522\n",
      "6 Validation accuracy: 0.9526\n",
      "7 Validation accuracy: 0.9552\n",
      "8 Validation accuracy: 0.9554\n",
      "9 Validation accuracy: 0.9562\n",
      "10 Validation accuracy: 0.9572\n",
      "11 Validation accuracy: 0.955\n",
      "12 Validation accuracy: 0.9572\n",
      "13 Validation accuracy: 0.9578\n",
      "14 Validation accuracy: 0.958\n",
      "15 Validation accuracy: 0.9568\n",
      "16 Validation accuracy: 0.9566\n",
      "17 Validation accuracy: 0.9574\n",
      "18 Validation accuracy: 0.9592\n",
      "19 Validation accuracy: 0.958\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Caching the Frozen Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:42:46.859887Z",
     "start_time": "2019-05-10T19:42:46.760566Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\") # reused frozen\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\") # reused frozen & cached\n",
    "    hidden2_stop = tf.stop_gradient(hidden2)\n",
    "    hidden3 = tf.layers.dense(hidden2_stop, n_hidden3, activation=tf.nn.relu,\n",
    "                              name=\"hidden3\") # reused, not frozen\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu,\n",
    "                              name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\") # new!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:42:53.934688Z",
     "start_time": "2019-05-10T19:42:53.913645Z"
    }
   },
   "outputs": [],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:43:07.859820Z",
     "start_time": "2019-05-10T19:43:02.680860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Validation accuracy: 0.9014\n",
      "1 Validation accuracy: 0.9308\n",
      "2 Validation accuracy: 0.9434\n",
      "3 Validation accuracy: 0.9476\n",
      "4 Validation accuracy: 0.9514\n",
      "5 Validation accuracy: 0.9522\n",
      "6 Validation accuracy: 0.9526\n",
      "7 Validation accuracy: 0.9552\n",
      "8 Validation accuracy: 0.9554\n",
      "9 Validation accuracy: 0.9562\n",
      "10 Validation accuracy: 0.9572\n",
      "11 Validation accuracy: 0.955\n",
      "12 Validation accuracy: 0.9572\n",
      "13 Validation accuracy: 0.9578\n",
      "14 Validation accuracy: 0.958\n",
      "15 Validation accuracy: 0.9568\n",
      "16 Validation accuracy: 0.9566\n",
      "17 Validation accuracy: 0.9574\n",
      "18 Validation accuracy: 0.9592\n",
      "19 Validation accuracy: 0.958\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_batches = len(X_train) // batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    \n",
    "    h2_cache = sess.run(hidden2, feed_dict={X: X_train})\n",
    "    h2_cache_valid = sess.run(hidden2, feed_dict={X: X_valid}) # not shown in the book\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        shuffled_idx = np.random.permutation(len(X_train))\n",
    "        hidden2_batches = np.array_split(h2_cache[shuffled_idx], n_batches)\n",
    "        y_batches = np.array_split(y_train[shuffled_idx], n_batches)\n",
    "        for hidden2_batch, y_batch in zip(hidden2_batches, y_batches):\n",
    "            sess.run(training_op, feed_dict={hidden2:hidden2_batch, y:y_batch})\n",
    "\n",
    "        accuracy_val = accuracy.eval(feed_dict={hidden2: h2_cache_valid, # not shown\n",
    "                                                y: y_valid})             # not shown\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)               # not shown\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Faster Optimizers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Momentum optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:23:00.636260Z",
     "start_time": "2019-05-11T16:23:00.633908Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Nesterov Accelarated Gradient**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:23:42.659669Z",
     "start_time": "2019-05-11T16:23:42.657369Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9, use_nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **AdaGrad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:24:20.071065Z",
     "start_time": "2019-05-11T16:24:20.068467Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RMSProp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:24:58.596921Z",
     "start_time": "2019-05-11T16:24:58.594339Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate, momentum=0.9, decay=0.9, epsilon=1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Adam Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:25:16.604216Z",
     "start_time": "2019-05-11T16:25:16.600944Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Learning Rate Scheduling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:25:59.692372Z",
     "start_time": "2019-05-11T16:25:59.650575Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:26:25.637508Z",
     "start_time": "2019-05-11T16:26:25.562544Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):\n",
    "    initial_learning_rate = 0.1\n",
    "    decay_steps = 10000\n",
    "    decay_rate = 1/10\n",
    "    global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "    learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step,\n",
    "                                               decay_steps, decay_rate)\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:27:22.291449Z",
     "start_time": "2019-05-11T16:27:22.272328Z"
    }
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:27:43.521993Z",
     "start_time": "2019-05-11T16:27:32.948144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.9602\n",
      "1 Validation accuracy: 0.9714\n",
      "2 Validation accuracy: 0.9776\n",
      "3 Validation accuracy: 0.9812\n",
      "4 Validation accuracy: 0.982\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Avoiding Overfitting Through Regularization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** $\\ell_1$ and $\\ell_2$ regularization**\n",
    "\n",
    "Let's implement $\\ell_1$ regularization manually. First, we create the model, as usual (with just one hidden layer this time, for simplicity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:34:30.722676Z",
     "start_time": "2019-05-11T16:34:30.696430Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    logits = tf.layers.dense(hidden1, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we get a handle on the layer weights, and we compute the total loss, which is equal to the sum of the usual cross entropy loss and the $\\ell_1$ loss (i.e., the absolute values of the weights):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:35:10.057581Z",
     "start_time": "2019-05-11T16:35:10.045802Z"
    }
   },
   "outputs": [],
   "source": [
    "W1 = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "W2 = tf.get_default_graph().get_tensor_by_name(\"outputs/kernel:0\")\n",
    "\n",
    "scale = 0.001 # l1 regularization hyperparameter\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")\n",
    "    reg_losses = tf.reduce_sum(tf.abs(W1)) + tf.reduce_sum(tf.abs(W2))\n",
    "    loss = tf.add(base_loss, scale * reg_losses, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest is just as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:35:22.272824Z",
     "start_time": "2019-05-11T16:35:22.221987Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:35:48.039130Z",
     "start_time": "2019-05-11T16:35:26.957020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.831\n",
      "1 Validation accuracy: 0.871\n",
      "2 Validation accuracy: 0.8838\n",
      "3 Validation accuracy: 0.8934\n",
      "4 Validation accuracy: 0.8966\n",
      "5 Validation accuracy: 0.8988\n",
      "6 Validation accuracy: 0.9016\n",
      "7 Validation accuracy: 0.9044\n",
      "8 Validation accuracy: 0.9058\n",
      "9 Validation accuracy: 0.906\n",
      "10 Validation accuracy: 0.9068\n",
      "11 Validation accuracy: 0.9054\n",
      "12 Validation accuracy: 0.907\n",
      "13 Validation accuracy: 0.9084\n",
      "14 Validation accuracy: 0.9088\n",
      "15 Validation accuracy: 0.9064\n",
      "16 Validation accuracy: 0.9066\n",
      "17 Validation accuracy: 0.9066\n",
      "18 Validation accuracy: 0.9066\n",
      "19 Validation accuracy: 0.9052\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can pass a regularization function to the tf.layers.dense() function, which will use it to create operations that will compute the regularization loss, and it adds these operations to the collection of regularization losses. The beginning is the same as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:36:14.598425Z",
     "start_time": "2019-05-11T16:36:14.592071Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use Python's partial() function to avoid repeating the same arguments over and over again. Note that we set the kernel_regularizer argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:36:24.554829Z",
     "start_time": "2019-05-11T16:36:24.552444Z"
    }
   },
   "outputs": [],
   "source": [
    "scale = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:36:38.182170Z",
     "start_time": "2019-05-11T16:36:32.154968Z"
    }
   },
   "outputs": [],
   "source": [
    "my_dense_layer = partial(\n",
    "    tf.layers.dense, activation=tf.nn.relu,\n",
    "    kernel_regularizer=tf.contrib.layers.l1_regularizer(scale))\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    hidden2 = my_dense_layer(hidden1, n_hidden2, name=\"hidden2\")\n",
    "    logits = my_dense_layer(hidden2, n_outputs, activation=None,\n",
    "                            name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next we must add the regularization losses to the base loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:37:08.949235Z",
     "start_time": "2019-05-11T16:37:08.941936Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):                                     \n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)                                \n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")   \n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    loss = tf.add_n([base_loss] + reg_losses, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the rest is the same as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:37:20.941290Z",
     "start_time": "2019-05-11T16:37:20.864850Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:37:49.527430Z",
     "start_time": "2019-05-11T16:37:27.135742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.8274\n",
      "1 Validation accuracy: 0.8766\n",
      "2 Validation accuracy: 0.8952\n",
      "3 Validation accuracy: 0.9016\n",
      "4 Validation accuracy: 0.908\n",
      "5 Validation accuracy: 0.9096\n",
      "6 Validation accuracy: 0.9124\n",
      "7 Validation accuracy: 0.9154\n",
      "8 Validation accuracy: 0.9178\n",
      "9 Validation accuracy: 0.919\n",
      "10 Validation accuracy: 0.92\n",
      "11 Validation accuracy: 0.9224\n",
      "12 Validation accuracy: 0.9212\n",
      "13 Validation accuracy: 0.9228\n",
      "14 Validation accuracy: 0.9222\n",
      "15 Validation accuracy: 0.9218\n",
      "16 Validation accuracy: 0.9218\n",
      "17 Validation accuracy: 0.9228\n",
      "18 Validation accuracy: 0.9216\n",
      "19 Validation accuracy: 0.9214\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now preferable to use tf.layers.dropout(), because anything in the contrib module may change or be deleted without notice. The tf.layers.dropout() function is almost identical to the tf.contrib.layers.dropout() function, except for a few minor differences. Most importantly:\n",
    "\n",
    "you must specify the dropout rate (rate) rather than the keep probability (keep_prob), where rate is simply equal to 1 - keep_prob,\n",
    "the is_training parameter is renamed to training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:39:16.129184Z",
     "start_time": "2019-05-11T16:39:16.122896Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:39:34.913305Z",
     "start_time": "2019-05-11T16:39:34.847126Z"
    }
   },
   "outputs": [],
   "source": [
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "dropout_rate = 0.5  # == 1 - keep_prob\n",
    "X_drop = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X_drop, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "    hidden2 = tf.layers.dense(hidden1_drop, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "    logits = tf.layers.dense(hidden2_drop, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:39:45.967227Z",
     "start_time": "2019-05-11T16:39:45.852681Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:40:51.099007Z",
     "start_time": "2019-05-11T16:39:53.401231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.9264\n",
      "1 Validation accuracy: 0.9452\n",
      "2 Validation accuracy: 0.9486\n",
      "3 Validation accuracy: 0.9562\n",
      "4 Validation accuracy: 0.9628\n",
      "5 Validation accuracy: 0.9596\n",
      "6 Validation accuracy: 0.964\n",
      "7 Validation accuracy: 0.9678\n",
      "8 Validation accuracy: 0.9694\n",
      "9 Validation accuracy: 0.9716\n",
      "10 Validation accuracy: 0.9696\n",
      "11 Validation accuracy: 0.9702\n",
      "12 Validation accuracy: 0.9712\n",
      "13 Validation accuracy: 0.9716\n",
      "14 Validation accuracy: 0.9706\n",
      "15 Validation accuracy: 0.9688\n",
      "16 Validation accuracy: 0.9728\n",
      "17 Validation accuracy: 0.9718\n",
      "18 Validation accuracy: 0.972\n",
      "19 Validation accuracy: 0.9728\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Max norm**\n",
    "\n",
    "Let's go back to a plain and simple neural net for MNIST with just 2 hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:41:25.250379Z",
     "start_time": "2019-05-11T16:41:25.152544Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's get a handle on the first hidden layer's weight and create an operation that will compute the clipped weights using the clip_by_norm() function. Then we create an assignment operation to assign the clipped weights to the weights variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:41:53.695289Z",
     "start_time": "2019-05-11T16:41:53.686887Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 1.0\n",
    "weights = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "clipped_weights = tf.clip_by_norm(weights, clip_norm=threshold, axes=1)\n",
    "clip_weights = tf.assign(weights, clipped_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this as well for the second hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:42:09.708662Z",
     "start_time": "2019-05-11T16:42:09.699655Z"
    }
   },
   "outputs": [],
   "source": [
    "weights2 = tf.get_default_graph().get_tensor_by_name(\"hidden2/kernel:0\")\n",
    "clipped_weights2 = tf.clip_by_norm(weights2, clip_norm=threshold, axes=1)\n",
    "clip_weights2 = tf.assign(weights2, clipped_weights2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add an initializer and a saver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:42:22.091724Z",
     "start_time": "2019-05-11T16:42:22.075238Z"
    }
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "And now we can train the model. It's pretty much as usual, except that right after running the training_op, we run the clip_weights and clip_weights2 operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:43:11.972529Z",
     "start_time": "2019-05-11T16:43:11.969750Z"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:44:34.415420Z",
     "start_time": "2019-05-11T16:43:18.488212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.9568\n",
      "1 Validation accuracy: 0.9696\n",
      "2 Validation accuracy: 0.9712\n",
      "3 Validation accuracy: 0.9774\n",
      "4 Validation accuracy: 0.9776\n",
      "5 Validation accuracy: 0.9782\n",
      "6 Validation accuracy: 0.981\n",
      "7 Validation accuracy: 0.9808\n",
      "8 Validation accuracy: 0.9806\n",
      "9 Validation accuracy: 0.9826\n",
      "10 Validation accuracy: 0.9826\n",
      "11 Validation accuracy: 0.9846\n",
      "12 Validation accuracy: 0.9832\n",
      "13 Validation accuracy: 0.9836\n",
      "14 Validation accuracy: 0.9838\n",
      "15 Validation accuracy: 0.9846\n",
      "16 Validation accuracy: 0.9844\n",
      "17 Validation accuracy: 0.9838\n",
      "18 Validation accuracy: 0.9848\n",
      "19 Validation accuracy: 0.9852\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:                                              \n",
    "    init.run()                                                          \n",
    "    for epoch in range(n_epochs):                                       \n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size): \n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            clip_weights.eval()\n",
    "            clip_weights2.eval()                                        \n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})   \n",
    "        print(epoch, \"Validation accuracy:\", acc_valid)                 \n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The implementation above is straightforward and it works fine, but it is a bit messy. A better approach is to define a max_norm_regularizer() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:48:02.639644Z",
     "start_time": "2019-05-11T16:48:02.635049Z"
    }
   },
   "outputs": [],
   "source": [
    "def max_norm_regularizer(threshold, axes=1, name=\"max_norm\",collection=\"max_norm\"):\n",
    "    def max_norm(weights):\n",
    "        clipped = tf.clip_by_norm(weights, clip_norm=threshold, axes=axes)\n",
    "        clip_weights = tf.assign(weights, clipped, name=name)\n",
    "        tf.add_to_collection(collection, clip_weights)\n",
    "        return None # there is no regularization loss term\n",
    "    return max_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then you can call this function to get a max norm regularizer (with the threshold you want). When you create a hidden layer, you can pass this regularizer to the kernel_regularizer argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:48:04.409197Z",
     "start_time": "2019-05-11T16:48:04.405235Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:48:05.314354Z",
     "start_time": "2019-05-11T16:48:05.128257Z"
    }
   },
   "outputs": [],
   "source": [
    "max_norm_reg = max_norm_regularizer(threshold=1.0)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:48:12.121729Z",
     "start_time": "2019-05-11T16:48:12.049108Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is as usual, except you must run the weights clipping operations after each training operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:49:16.644980Z",
     "start_time": "2019-05-11T16:49:16.642935Z"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T16:50:40.244788Z",
     "start_time": "2019-05-11T16:49:30.974342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.9556\n",
      "1 Validation accuracy: 0.9706\n",
      "2 Validation accuracy: 0.9686\n",
      "3 Validation accuracy: 0.9738\n",
      "4 Validation accuracy: 0.9764\n",
      "5 Validation accuracy: 0.976\n",
      "6 Validation accuracy: 0.9806\n",
      "7 Validation accuracy: 0.9804\n",
      "8 Validation accuracy: 0.9834\n",
      "9 Validation accuracy: 0.9814\n",
      "10 Validation accuracy: 0.9804\n",
      "11 Validation accuracy: 0.9828\n",
      "12 Validation accuracy: 0.982\n",
      "13 Validation accuracy: 0.9826\n",
      "14 Validation accuracy: 0.984\n",
      "15 Validation accuracy: 0.984\n",
      "16 Validation accuracy: 0.9824\n",
      "17 Validation accuracy: 0.983\n",
      "18 Validation accuracy: 0.9838\n",
      "19 Validation accuracy: 0.984\n"
     ]
    }
   ],
   "source": [
    "clip_all_weights = tf.get_collection(\"max_norm\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            sess.run(clip_all_weights)\n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid}) \n",
    "        print(epoch, \"Validation accuracy:\", acc_valid)               \n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------- END ----------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
